Start of 3000 iterations with learning rate 0.0010
2023-05-08 06:47:05.903228
Training loss at step 100: 0.000006
Training categorical accuracy at step 100: 0.964415
2023-05-08 07:04:54.040137
Training loss at step 200: 0.010152
Training categorical accuracy at step 200: 0.970881
2023-05-08 07:22:42.143206
Training loss at step 300: 0.000008
Training categorical accuracy at step 300: 0.976920
2023-05-08 07:40:29.711662
Training loss at step 400: 0.004763
Training categorical accuracy at step 400: 0.981355
2023-05-08 07:58:17.138415
Training loss at step 500: 0.000109
Training categorical accuracy at step 500: 0.984279
2023-05-08 08:16:04.750737
Training loss at step 600: 0.000002
Training categorical accuracy at step 600: 0.986493
2023-05-08 08:33:53.635057
Training loss at step 700: 0.000255
Training categorical accuracy at step 700: 0.988202
2023-05-08 08:51:42.618750
Training loss at step 800: 0.000045
Training categorical accuracy at step 800: 0.989425
2023-05-08 09:09:31.094228
Training loss at step 900: 0.000044
Training categorical accuracy at step 900: 0.990279
2023-05-08 09:27:19.829203
Training loss at step 1000: 0.002108
Training categorical accuracy at step 1000: 0.991068
2023-05-08 09:45:08.482173
Training loss at step 1100: 0.000034
Training categorical accuracy at step 1100: 0.991762
2023-05-08 10:02:57.667568
Training loss at step 1200: 0.000134
Training categorical accuracy at step 1200: 0.992350
2023-05-08 10:20:45.764770
Training loss at step 1300: 0.000001
Training categorical accuracy at step 1300: 0.992847
2023-05-08 10:38:34.354962
Training loss at step 1400: 0.072615
Training categorical accuracy at step 1400: 0.993265
2023-05-08 10:56:22.497879
Training loss at step 1500: 0.000002
Training categorical accuracy at step 1500: 0.993628
2023-05-08 11:14:11.021341
Training loss at step 1600: 0.000522
Training categorical accuracy at step 1600: 0.993949
2023-05-08 11:32:00.292318
Training loss at step 1700: 0.000310
Training categorical accuracy at step 1700: 0.994246
2023-05-08 11:49:49.552418
Training loss at step 1800: 0.375825
Training categorical accuracy at step 1800: 0.994493
2023-05-08 12:07:39.348852
Training loss at step 1900: 0.000587
Training categorical accuracy at step 1900: 0.994727
2023-05-08 12:25:28.294148
Training loss at step 2000: 0.001734
Training categorical accuracy at step 2000: 0.994955
2023-05-08 12:43:17.569735
Training loss at step 2100: 0.000009
Training categorical accuracy at step 2100: 0.995159
2023-05-08 13:01:07.290856
Training loss at step 2200: 0.000831
Training categorical accuracy at step 2200: 0.995334
2023-05-08 13:18:55.782846
Training loss at step 2300: 0.000137
Training categorical accuracy at step 2300: 0.995496
2023-05-08 13:36:44.413831
Training loss at step 2400: 0.000364
Training categorical accuracy at step 2400: 0.995651
2023-05-08 13:54:33.773372
Training loss at step 2500: 0.000043
Training categorical accuracy at step 2500: 0.995809
2023-05-08 14:12:22.437756
Training loss at step 2600: 0.000034
Training categorical accuracy at step 2600: 0.995922
2023-05-08 14:30:11.278587
Training loss at step 2700: 0.000026
Training categorical accuracy at step 2700: 0.996058
2023-05-08 14:48:00.187630
Training loss at step 2800: 0.000014
Training categorical accuracy at step 2800: 0.996165
2023-05-08 15:05:49.945407
Training loss at step 2900: 0.000025
Training categorical accuracy at step 2900: 0.996269
Time taken: 32069.99s
Start of 2000 iterations with learning rate 0.0001
2023-05-08 15:41:34.670756
Training loss at step 100: 0.000021
Training categorical accuracy at step 100: 0.999592
2023-05-08 15:59:26.927935
Training loss at step 200: 0.000011
Training categorical accuracy at step 200: 0.999678
2023-05-08 16:17:23.924252
Training loss at step 300: 0.000740
Training categorical accuracy at step 300: 0.999648
2023-05-08 16:35:19.493277
Training loss at step 400: 0.000331
Training categorical accuracy at step 400: 0.999707
2023-05-08 16:53:13.217577
Training loss at step 500: 0.000007
Training categorical accuracy at step 500: 0.999671
2023-05-08 17:11:23.800648
Training loss at step 600: 0.000006
Training categorical accuracy at step 600: 0.999697
2023-05-08 17:29:55.041346
Training loss at step 700: 0.000012
Training categorical accuracy at step 700: 0.999681
2023-05-08 17:47:48.032913
Training loss at step 800: 0.000723
Training categorical accuracy at step 800: 0.999677
2023-05-08 18:05:40.756799
Training loss at step 900: 0.000020
Training categorical accuracy at step 900: 0.999687
2023-05-08 18:23:34.259517
Training loss at step 1000: 0.000001
Training categorical accuracy at step 1000: 0.999677
2023-05-08 18:41:27.412428
Training loss at step 1100: 0.000029
Training categorical accuracy at step 1100: 0.999690
2023-05-08 18:59:20.013150
Training loss at step 1200: 0.000013
Training categorical accuracy at step 1200: 0.999706
2023-05-08 19:17:10.452328
Training loss at step 1300: 0.000008
Training categorical accuracy at step 1300: 0.999720
2023-05-08 19:35:03.284299
Training loss at step 1400: 0.000001
Training categorical accuracy at step 1400: 0.999735
2023-05-08 19:52:58.042235
Training loss at step 1500: 0.000001
Training categorical accuracy at step 1500: 0.999749
2023-05-08 20:10:52.721796
Training loss at step 1600: 0.000002
Training categorical accuracy at step 1600: 0.999739
2023-05-08 20:28:46.979914
Training loss at step 1700: 0.001014
Training categorical accuracy at step 1700: 0.999737
2023-05-08 20:46:39.387994
Training loss at step 1800: 0.000017
Training categorical accuracy at step 1800: 0.999729
2023-05-08 21:04:31.237035
Training loss at step 1900: 0.000008
Training categorical accuracy at step 1900: 0.999734
Time taken: 21521.84s
Start of 1000 iterations with learning rate 0.00001
2023-05-08 21:40:18.444446
Training loss at step 100: 0.000000
Training categorical accuracy at step 100: 0.999884
2023-05-08 21:58:09.308080
Training loss at step 200: 0.000320
Training categorical accuracy at step 200: 0.999883
2023-05-08 22:16:00.856490
Training loss at step 300: 0.000006
Training categorical accuracy at step 300: 0.999785
2023-05-08 22:33:54.220661
Training loss at step 400: 0.000001
Training categorical accuracy at step 400: 0.999809
2023-05-08 22:51:48.518362
Training loss at step 500: 0.000006
Training categorical accuracy at step 500: 0.999777
2023-05-08 23:09:42.448844
Training loss at step 600: 0.000009
Training categorical accuracy at step 600: 0.999814
2023-05-08 23:27:36.205788
Training loss at step 700: 0.000003
Training categorical accuracy at step 700: 0.999782
2023-05-08 23:45:31.092226
Training loss at step 800: 0.000011
Training categorical accuracy at step 800: 0.999780
2023-05-09 00:03:25.055188
Training loss at step 900: 0.000009
Training categorical accuracy at step 900: 0.999791
Time taken: 10734.70s
