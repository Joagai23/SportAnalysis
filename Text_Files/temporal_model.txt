Start of 3000 iterations with learning rate 0.0010
2023-05-10 10:44:27.777561
Training loss at step 100: 0.010357
Training categorical accuracy at step 100: 0.866045
2023-05-10 11:08:45.007208
Training loss at step 200: 0.000109
Training categorical accuracy at step 200: 0.893913
2023-05-10 11:32:12.652357
Training loss at step 300: 0.005388
Training categorical accuracy at step 300: 0.909693
2023-05-10 11:55:43.878670
Training loss at step 400: 0.002254
Training categorical accuracy at step 400: 0.922781
2023-05-10 12:19:31.677866
Training loss at step 500: 0.000017
Training categorical accuracy at step 500: 0.934120
2023-05-10 12:42:37.494115
Training loss at step 600: 0.000144
Training categorical accuracy at step 600: 0.943134
2023-05-10 13:05:50.066387
Training loss at step 700: 0.000004
Training categorical accuracy at step 700: 0.949912
2023-05-10 13:29:12.700071
Training loss at step 800: 0.000000
Training categorical accuracy at step 800: 0.955460
2023-05-10 13:52:26.452153
Training loss at step 900: 0.001897
Training categorical accuracy at step 900: 0.959979
2023-05-10 14:15:43.807418
Training loss at step 1000: 0.000000
Training categorical accuracy at step 1000: 0.963654
2023-05-10 14:38:44.701122
Training loss at step 1100: 0.000007
Training categorical accuracy at step 1100: 0.966763
2023-05-10 15:01:50.250356
Training loss at step 1200: 0.092439
Training categorical accuracy at step 1200: 0.969285
2023-05-10 15:24:54.728323
Training loss at step 1300: 0.000002
Training categorical accuracy at step 1300: 0.971538
2023-05-10 15:47:58.374388
Training loss at step 1400: 0.000000
Training categorical accuracy at step 1400: 0.973427
2023-05-10 16:11:02.711661
Training loss at step 1500: 0.000000
Training categorical accuracy at step 1500: 0.975154
2023-05-10 16:34:07.333692
Training loss at step 1600: 0.000000
Training categorical accuracy at step 1600: 0.976684
2023-05-10 16:57:04.974652
Training loss at step 1700: 0.000000
Training categorical accuracy at step 1700: 0.978013
2023-05-10 17:20:06.193373
Training loss at step 1800: 0.000000
Training categorical accuracy at step 1800: 0.979230
2023-05-10 17:43:04.389786
Training loss at step 1900: 0.000001
Training categorical accuracy at step 1900: 0.980320
2023-05-10 18:06:10.610217
Training loss at step 2000: 0.000001
Training categorical accuracy at step 2000: 0.981298
2023-05-10 18:29:13.888669
Training loss at step 2100: 0.000000
Training categorical accuracy at step 2100: 0.982185
2023-05-10 18:52:17.278292
Training loss at step 2200: 0.000000
Training categorical accuracy at step 2200: 0.982994
2023-05-10 19:15:24.104127
Training loss at step 2300: 0.000000
Training categorical accuracy at step 2300: 0.983726
2023-05-10 19:38:43.302481
Training loss at step 2400: 0.000000
Training categorical accuracy at step 2400: 0.984401
2023-05-10 20:02:51.319793
Training loss at step 2500: 0.000000
Training categorical accuracy at step 2500: 0.985025
2023-05-10 20:26:23.209944
Training loss at step 2600: 0.000000
Training categorical accuracy at step 2600: 0.985598
2023-05-10 20:48:16.202434
Training loss at step 2700: 0.000000
Training categorical accuracy at step 2700: 0.986127
2023-05-10 21:10:54.318325
Training loss at step 2800: 0.000000
Training categorical accuracy at step 2800: 0.986620
2023-05-10 21:34:28.934552
Training loss at step 2900: 0.000000
Training categorical accuracy at step 2900: 0.987082
Time taken: 42166.99s
Start of 2000 iterations with learning rate 0.0001
2023-05-10 22:26:09.158923
Training loss at step 100: 0.000000
Training categorical accuracy at step 100: 0.999942
2023-05-10 22:48:14.128436
Training loss at step 200: 0.000000
Training categorical accuracy at step 200: 0.999941
2023-05-10 23:10:32.356971
Training loss at step 300: 0.000000
Training categorical accuracy at step 300: 0.999961
2023-05-10 23:32:24.610007
Training loss at step 400: 0.000000
Training categorical accuracy at step 400: 0.999971
2023-05-10 23:54:04.562730
Training loss at step 500: 0.000000
Training categorical accuracy at step 500: 0.999977
2023-05-11 00:15:47.544199
Training loss at step 600: 0.000000
Training categorical accuracy at step 600: 0.999961
2023-05-11 00:37:38.912322
Training loss at step 700: 0.000000
Training categorical accuracy at step 700: 0.999966
2023-05-11 00:59:20.920316
Training loss at step 800: 0.000465
Training categorical accuracy at step 800: 0.999963
2023-05-11 01:21:02.447715
Training loss at step 900: 0.000000
Training categorical accuracy at step 900: 0.999967
2023-05-11 01:42:45.595173
Training loss at step 1000: 0.000000
Training categorical accuracy at step 1000: 0.999965
2023-05-11 02:04:28.140952
Training loss at step 1100: 0.000000
Training categorical accuracy at step 1100: 0.999968
2023-05-11 02:26:10.144952
Training loss at step 1200: 0.000007
Training categorical accuracy at step 1200: 0.999966
2023-05-11 02:47:51.669025
Training loss at step 1300: 0.000000
Training categorical accuracy at step 1300: 0.999964
2023-05-11 03:09:33.239536
Training loss at step 1400: 0.000000
Training categorical accuracy at step 1400: 0.999966
2023-05-11 03:31:13.588179
Training loss at step 1500: 0.000000
Training categorical accuracy at step 1500: 0.999969
2023-05-11 03:52:54.351344
Training loss at step 1600: 0.000000
Training categorical accuracy at step 1600: 0.999967
2023-05-11 04:14:35.915794
Training loss at step 1700: 0.000001
Training categorical accuracy at step 1700: 0.999965
2023-05-11 04:36:17.661299
Training loss at step 1800: 0.000000
Training categorical accuracy at step 1800: 0.999964
2023-05-11 04:57:59.600986
Training loss at step 1900: 0.000000
Training categorical accuracy at step 1900: 0.999957
Time taken: 26178.90s
Start of 1000 iterations with learning rate 0.00001
2023-05-11 05:41:30.839529
Training loss at step 100: 0.000000
Training categorical accuracy at step 100: 0.999942
2023-05-11 06:03:13.759292
Training loss at step 200: 0.000000
Training categorical accuracy at step 200: 0.999971
2023-05-11 06:24:59.721631
Training loss at step 300: 0.000002
Training categorical accuracy at step 300: 0.999980
2023-05-11 06:46:46.923145
Training loss at step 400: 0.000000
Training categorical accuracy at step 400: 0.999985
2023-05-11 07:08:29.455604
Training loss at step 500: 0.000002
Training categorical accuracy at step 500: 0.999988
2023-05-11 07:30:16.276213
Training loss at step 600: 0.000000
Training categorical accuracy at step 600: 0.999990
2023-05-11 07:51:56.195032
Training loss at step 700: 0.000000
Training categorical accuracy at step 700: 0.999992
2023-05-11 08:13:46.747598
Training loss at step 800: 0.000000
Training categorical accuracy at step 800: 0.999993
2023-05-11 08:35:28.514318
Training loss at step 900: 0.000000
Training categorical accuracy at step 900: 0.999980
Time taken: 13041.27s
